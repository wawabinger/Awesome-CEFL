# Contributions Estimation in Federated Learning: A Comprehensive Experimental Evaluation



### 1.1 Data Utility Metrics

#### 1.1.1 Test-set-dependent Metrics

- Accuracy(分类任务)，Macro F1更适合class imbalance
- R2(回归任务)

#### 1.1.2 Test-set-independent Metrics

- Statistical Metrics
  - 数据量
  - 数据多样性：volume和robust volume（Validation free and replication robust volume-based data valuation0-Neurips 2021）
- Model Parameter Metrics
  - 梯度相似性
  - 模型不确定性（Collaborative machine learning with incentive-aware model rewards-PMLR 2021）

### 1.2 Contribution Estimation Method

- Individual：客户端报告自己的data utility
- LeaveOneOut（LOO）：客户端加入前后的效用变化
- ShapleyValue（SV）：相比于LOO只考虑一种组合，SV考虑所有可能的组合带来的效用变化，更关注individual fairness
- LeastCore：core是指客户端在利益分配时的一个稳定联盟，此时不会有联盟通过分裂出去获得更高的收益，但当无法满足时，会放松条件寻求次优解，即LeastCore。更关注group fairness

### 1.3 Optimization Techiniques

- Smapling
  - Random
  - Structured
  - Guided
  - Sub
- Graidient reuse
  - One-round
  - Multi-round

### 1.4 Experiment Findings

- **关于有效性（Effectiveness）**：

  - Shapley值方法在不同的数据集和联邦学习场景下表现出最有效的性能，因为它通过广泛的枚举来识别客户端在联盟中的边际贡献。

  - 在数据量偏斜的联邦学习环境中，Individual方案几乎可以与Shapley值相匹配，但在数据标签偏斜的环境中，它的性能则较为适中。

- **关于鲁棒性（Robustness）**：

  - Individual方案显示出对所有不利行为的最高鲁棒性，因为它可以准确反映个别客户端数据质量的影响。

  - Shapley值和StructuredMC-Shapley方案对于数据复制和随机数据生成行为表现出一定的鲁棒性，它们的平均相对变化接近零或为负。

  - LeaveOneOut方案对于不利行为的鲁棒性较低，因为它的结果变化较大且许多变化为正。

- **关于效率（Efficiency）**：

  - Shapley值和LeastCore方案由于需要枚举所有可能的联盟，因此计算成本最高。

  - 结构化蒙特卡洛Shapley（StructuredMC-Shapley）和蒙特卡洛最小核心（MC-LeastCore）方案虽然采用了采样优化，但计算需求仍然相对较高。

  - Individual、LeaveOneOut和多轮重用（MultiRounds）方案在实践中被发现是最高效的。

- **关于数据效用度量（Data Utility Metrics）**：

  - 在没有不利行为的情况下，DataQuantity和CosineGradient可以作为Accuracy的替代品，尤其是在数据量偏斜的数据集中。

  - 在存在大量标签翻转等不利行为的情况下，没有现有的度量可以完全替代Accuracy。

- **关于优化技术（Optimization Techniques）**：
  - 采样和梯度重用技术可以有效地优化FLCE过程，但它们的实际效果和效率仍需进一步研究。

