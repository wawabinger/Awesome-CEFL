# ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning

目的：恶意客户端的数据集质量低，但是却想要让服务器认为他做出了较好的贡献以获得超额的奖励

### 1.1 Future Global Model Prediction

柯西均值定理来预测全局模型更新

$g^t = g^{t−1} + H^t (w^t − w^{t−1})$

其中$H$为Hessian矩阵，用L-BFGS 算法来接近该矩阵, 

### 1.2 Prediction Error Mitigation：

- 在初始轮次缺乏历史信息，应对策略是在初始轮次正常训练
- 误差随轮次的积累而变大，应对措施是用L-BFGS算法中计算的Hessian-vector乘积，代表预测误差，并设置一个thrshold

### 1.3 Strategies to Enhance ACE:

- 针对使用余弦相似度的贡献评估：放大模型更新，使更新占主导地位
- 针对使用validation的贡献评估：在一个通信轮次内多次执行L-BFGS来生成一个精度更高的update

### 1.4 Experiment:

三种划分方式：同质，异质（不同数据集大小），异质（不同类别）

四个baseline：老实训练，delta weight（每次更新加一个高斯噪声），data augment（玩弄你的数据集，缩放重组截取），scaling attack

对应的贡献评估方法有FedSV，LOO，CFFL，GDR